{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qm2oRKv26-hB",
        "N7_j7cE5GIVJ",
        "PPBeEUrwIx0T",
        "M5JW8c4CbtU5"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the Dataset\n",
        "\n",
        "Dataset Source: https://www.kaggle.com/competitions/global-wheat-detection\n",
        "\n",
        "Before attempting to download the dataset, you have to get your kaggle API key and your kaggle username and set it to the google colab secrets as \"KAGGLE_USERNAME\" and \"KAGGLE_KEY\"."
      ],
      "metadata": {
        "id": "qm2oRKv26-hB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmQJGc-U6aif"
      },
      "outputs": [],
      "source": [
        "# Mount the Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Kaggle API authentication\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import zipfile\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
        "os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\n",
        "\n",
        "# Import kaggle\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "# Initialize and authenticate Kaggle API\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "print(\"Kaggle API authenticated successfully!\")"
      ],
      "metadata": {
        "id": "4HccIgzW7HgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure dataset is downloaded via Kaggle API\n",
        "!kaggle competitions download -c global-wheat-detection -p /content/\n",
        "\n",
        "# Extract the dataset and verify extraction\n",
        "\n",
        "import zipfile\n",
        "\n",
        "# Path to the downloaded dataset\n",
        "zip_path = '/content/global-wheat-detection.zip'\n",
        "extract_to = '/content/global-wheat-detection'\n",
        "\n",
        "# Extract the dataset\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(f\"Dataset extracted to: {extract_to}\")"
      ],
      "metadata": {
        "id": "IbB7rMbk8c2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Faster R-CNN model without Augmentation"
      ],
      "metadata": {
        "id": "Ua10jGQDGDpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "N7_j7cE5GIVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU available\")"
      ],
      "metadata": {
        "id": "kI43BP1qGLq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the train.csv file\n",
        "csv_file = '/content/global-wheat-detection/train.csv'\n",
        "data = pd.read_csv(csv_file)\n",
        "\n",
        "# Convert COCO bounding box format to Faster R-CNN format\n",
        "def coco_to_frcnn(bbox):\n",
        "    x_min, y_min, width, height = bbox\n",
        "    x_max = x_min + width\n",
        "    y_max = y_min + height\n",
        "    return [x_min, y_min, x_max, y_max]\n",
        "\n",
        "# Parse bounding boxes from the dataframe\n",
        "# Assuming `bbox` column contains strings in the format: \"[x_min, y_min, width, height]\"\n",
        "data['bbox'] = data['bbox'].apply(eval)                                         # Convert string to list\n",
        "data['bbox_frcnn'] = data['bbox'].apply(coco_to_frcnn)\n",
        "\n",
        "# Group data by image_id to collect all bounding boxes for each image\n",
        "annotations = {}\n",
        "for image_id, group in data.groupby('image_id'):\n",
        "    boxes = group['bbox_frcnn'].tolist()\n",
        "    annotations[image_id] = {\n",
        "        \"boxes\": torch.tensor(boxes, dtype=torch.float32),\n",
        "        \"labels\": torch.tensor([1] * len(boxes), dtype=torch.int64)             # Assuming 1 class for wheat\n",
        "    }\n",
        "\n",
        "# Split data into train and validation sets\n",
        "image_ids = list(annotations.keys())\n",
        "train_ids, val_ids = train_test_split(image_ids, test_size=0.2, random_state=42)\n",
        "\n",
        "# Dataset class\n",
        "class WheatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, image_ids, annotations, image_dir, transforms=None):\n",
        "        self.image_ids = image_ids\n",
        "        self.annotations = annotations\n",
        "        self.image_dir = image_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_id = self.image_ids[idx]\n",
        "        image_path = f\"{self.image_dir}/{image_id}.jpg\"\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        target = self.annotations[image_id]\n",
        "\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "# Paths to images\n",
        "data_dir = '/content/global-wheat-detection/train'\n",
        "\n",
        "# Define datasets\n",
        "train_dataset = WheatDataset(train_ids, annotations, data_dir, transforms=F.to_tensor)\n",
        "val_dataset = WheatDataset(val_ids, annotations, data_dir, transforms=F.to_tensor)\n",
        "\n",
        "# DataLoader\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "# Verify data loading\n",
        "if __name__ == \"__main__\":\n",
        "    for images, targets in train_loader:\n",
        "        print(\"Images:\", images)\n",
        "        print(\"Targets:\", targets)\n",
        "        break"
      ],
      "metadata": {
        "id": "ww1H1hR9GdpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First Dry Run (SGD as optimizer)"
      ],
      "metadata": {
        "id": "PPBeEUrwIx0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "import time\n",
        "import os\n",
        "import torchvision.ops as ops\n",
        "\n",
        "# Define and load the model\n",
        "# Ensure compatibility for both Google Colab and Kaggle\n",
        "if \"google.colab\" in str(get_ipython()):\n",
        "    save_dir = \"/content/global-wheat-detection/FirstModel\"\n",
        "else:\n",
        "    save_dir = \"/kaggle/working/FirstModel\"\n",
        "\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "def get_model():\n",
        "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    num_classes = 2                                                             # 1 class (wheat) + background\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "\n",
        "# Move model to device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "# IoU computation\n",
        "def compute_iou(pred_boxes, gt_boxes):\n",
        "    if len(pred_boxes) == 0 or len(gt_boxes) == 0:\n",
        "        return 0.0                                                              # No detections or ground truth\n",
        "    iou = ops.box_iou(pred_boxes, gt_boxes)\n",
        "    return iou.mean().item()\n",
        "\n",
        "# Training loop\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch_idx, (images, targets) in enumerate(data_loader):\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_loss = losses.item()\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Batch {batch_idx + 1}/{len(data_loader)}, Loss: {batch_loss:.4f}\")\n",
        "\n",
        "    average_loss = total_loss / len(data_loader)\n",
        "    print(f\"Epoch {epoch + 1} Training Loss: {average_loss:.4f}\")\n",
        "    return average_loss\n",
        "\n",
        "# Validation loop\n",
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    total_iou = 0.0\n",
        "    num_batches = 0\n",
        "    print(\"Running validation...\")\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, targets) in enumerate(data_loader):\n",
        "            images = [img.to(device) for img in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            predictions = model(images)\n",
        "            batch_iou = 0.0\n",
        "            for pred, target in zip(predictions, targets):\n",
        "                pred_boxes = pred[\"boxes\"].detach().cpu()\n",
        "                gt_boxes = target[\"boxes\"].detach().cpu()\n",
        "                batch_iou += compute_iou(pred_boxes, gt_boxes)\n",
        "\n",
        "            avg_batch_iou = batch_iou / len(images) if len(images) > 0 else 0\n",
        "            total_iou += avg_batch_iou\n",
        "            num_batches += 1\n",
        "\n",
        "            print(f\"Validation Batch {batch_idx + 1}/{len(data_loader)}, IoU: {avg_batch_iou:.4f}\")\n",
        "\n",
        "    avg_iou = total_iou / num_batches if num_batches > 0 else None\n",
        "    print(f\"Validation completed. Avg IoU: {avg_iou:.4f}\")\n",
        "    return None, avg_iou                                                        # No validation loss\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {'epoch': [], 'train_loss': [], 'val_loss': [], 'val_iou': []}\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10                                                                 # Number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Starting Epoch {epoch + 1}/{num_epochs}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
        "    print(\"Evaluating on validation set...\")\n",
        "    _, val_iou = evaluate(model, val_loader, device)                            # No validation loss\n",
        "\n",
        "    results['epoch'].append(epoch + 1)\n",
        "    results['train_loss'].append(train_loss)\n",
        "    results['val_loss'].append(None)                                            # No validation loss\n",
        "    results['val_iou'].append(val_iou)\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(os.path.join(save_dir, 'training_results.csv'), index=False)\n",
        "\n",
        "    checkpoint_path = os.path.join(save_dir, f'model_epoch_{epoch + 1}.pth')\n",
        "    torch.save(model.state_dict(), checkpoint_path)\n",
        "    print(f\"Saved model checkpoint to {checkpoint_path}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Epoch {epoch + 1} completed in {(end_time - start_time):.2f} seconds\")\n",
        "    print(f\"Epoch {epoch + 1} Summary: Train Loss: {train_loss:.4f}, Validation IoU: {val_iou:.4f}\\n\")\n",
        "\n",
        "# Plot results\n",
        "def plot_results(results_csv):\n",
        "    import matplotlib.pyplot as plt\n",
        "    results_df = pd.read_csv(results_csv)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.plot(results_df['epoch'], results_df['train_loss'], label='Train Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.plot(results_df['epoch'], results_df['val_iou'], label='Validation IoU', color='green')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('IoU')\n",
        "    plt.title('Validation IoU Over Epochs')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_results(os.path.join(save_dir, 'training_results.csv'))"
      ],
      "metadata": {
        "id": "bkUoeFVYIyz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import os\n",
        "\n",
        "# Load the trained model\n",
        "model_path = os.path.join(save_dir, f'model_epoch_{num_epochs}.pth')            # Load the last epoch model\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# Define image path\n",
        "test_image_id = \"f5a1f0358\"                                                     # Update with actual test image ID\n",
        "\n",
        "# Handle path for both Colab and Kaggle\n",
        "if \"google.colab\" in str(get_ipython()):\n",
        "    test_dir = \"/content/global-wheat-detection/data/test\"\n",
        "else:\n",
        "    test_dir = \"/kaggle/input/global-wheat-detection/test\"\n",
        "\n",
        "# Get test images\n",
        "test_image_path = os.path.join(test_dir, f\"{test_image_id}.jpg\")\n",
        "\n",
        "# Load image\n",
        "image = Image.open(test_image_path).convert(\"RGB\")\n",
        "transform = T.ToTensor()\n",
        "image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "# Get model predictions\n",
        "with torch.no_grad():\n",
        "    predictions = model(image_tensor)\n",
        "\n",
        "# Extract predicted boxes & scores\n",
        "pred_boxes = predictions[0][\"boxes\"].cpu().numpy()\n",
        "scores = predictions[0][\"scores\"].cpu().numpy()\n",
        "\n",
        "# Set confidence threshold\n",
        "confidence_threshold = 0.5\n",
        "filtered_boxes = pred_boxes[scores > confidence_threshold]\n",
        "\n",
        "# Plot the image\n",
        "fig, ax = plt.subplots(1, figsize=(8, 6))\n",
        "ax.imshow(image)\n",
        "\n",
        "\n",
        "# Draw bounding boxes\n",
        "for box in filtered_boxes:\n",
        "    x_min, y_min, x_max, y_max = box\n",
        "    rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=2, edgecolor=\"r\", facecolor=\"none\")\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "plt.title(\"Predicted Bounding Boxes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YZCwEGCXMji1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "import time\n",
        "import os\n",
        "import torchvision.ops as ops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Define the model\n",
        "def get_model():\n",
        "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    num_classes = 2  # 1 class (wheat) + background\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "\n",
        "# Move model to device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Load trained model\n",
        "model_path = os.path.join(save_dir, f'model_epoch_{num_epochs}.pth')\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# Function to visualize bounding boxes with labels\n",
        "def visualize_predictions(image_path, model, device, confidence_threshold=0.5):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    transform = T.ToTensor()\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model(image_tensor)\n",
        "\n",
        "    pred_boxes = predictions[0][\"boxes\"].cpu().numpy()\n",
        "    scores = predictions[0][\"scores\"].cpu().numpy()\n",
        "\n",
        "    filtered_boxes = pred_boxes[scores > confidence_threshold]\n",
        "    filtered_scores = scores[scores > confidence_threshold]\n",
        "\n",
        "    fig, ax = plt.subplots(1, figsize=(8, 6))\n",
        "    ax.imshow(image)\n",
        "\n",
        "    for box, score in zip(filtered_boxes, filtered_scores):\n",
        "        x_min, y_min, x_max, y_max = box\n",
        "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=2, edgecolor=\"r\", facecolor=\"none\")\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(x_min, y_min - 5, f'{score:.2f}', color='red', fontsize=10, weight='bold', bbox=dict(facecolor='white', alpha=0.5))\n",
        "\n",
        "    image_name = os.path.basename(image_path)\n",
        "    plt.title(f\"Predicted Bounding Boxes - {image_name}\")\n",
        "    plt.show()\n",
        "\n",
        "# Define test image path for Kaggle\n",
        "if \"google.colab\" in str(get_ipython()):\n",
        "    test_dir = \"/content/global-wheat-detection/data/test\"\n",
        "else:\n",
        "    test_dir = \"/kaggle/input/global-wheat-detection/test\"\n",
        "\n",
        "# Get test image\n",
        "test_image_path = os.path.join(test_dir, f\"{test_image_id}.jpg\")\n",
        "\n",
        "# Visualize bounding boxes for up to 10 test images\n",
        "for img_path in test_images[:10]:\n",
        "    visualize_predictions(img_path, model, device)"
      ],
      "metadata": {
        "id": "K1UiXvnUNdHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Second Dry Run (Adam as optimizer and learning rate scheduler)"
      ],
      "metadata": {
        "id": "M5JW8c4CbtU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "import time\n",
        "import os\n",
        "import torchvision.ops as ops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Define and load the model\n",
        "# Ensure compatibility for both Google Colab and Kaggle\n",
        "if \"google.colab\" in str(get_ipython()):\n",
        "    save_dir = \"/content/global-wheat-detection/SecondModel\"\n",
        "else:\n",
        "    save_dir = \"/kaggle/working/SecondModel\"\n",
        "\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "def get_model():\n",
        "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    num_classes = 2                                                             # 1 class (wheat) + background\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "\n",
        "# Move model to device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and learning rate scheduler\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.0001)\n",
        "\n",
        "# Learning rate scheduler - Reduce LR when validation IoU plateaus\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "# IoU computation\n",
        "def compute_iou(pred_boxes, gt_boxes):\n",
        "    if len(pred_boxes) == 0 or len(gt_boxes) == 0:\n",
        "        return 0.0                                                              # No detections or ground truth\n",
        "    iou = ops.box_iou(pred_boxes, gt_boxes)\n",
        "    return iou.mean().item()\n",
        "\n",
        "# Training loop\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch_idx, (images, targets) in enumerate(data_loader):\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_loss = losses.item()\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Batch {batch_idx + 1}/{len(data_loader)}, Loss: {batch_loss:.4f}\")\n",
        "\n",
        "    average_loss = total_loss / len(data_loader)\n",
        "    print(f\"Epoch {epoch + 1} Training Loss: {average_loss:.4f}\")\n",
        "    return average_loss\n",
        "\n",
        "# Validation loop\n",
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    total_iou = 0.0\n",
        "    num_batches = 0\n",
        "    print(\"Running validation...\")\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, targets) in enumerate(data_loader):\n",
        "            images = [img.to(device) for img in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            predictions = model(images)\n",
        "            batch_iou = 0.0\n",
        "            for pred, target in zip(predictions, targets):\n",
        "                pred_boxes = pred[\"boxes\"].detach().cpu()\n",
        "                gt_boxes = target[\"boxes\"].detach().cpu()\n",
        "                batch_iou += compute_iou(pred_boxes, gt_boxes)\n",
        "\n",
        "            avg_batch_iou = batch_iou / len(images) if len(images) > 0 else 0\n",
        "            total_iou += avg_batch_iou\n",
        "            num_batches += 1\n",
        "\n",
        "            print(f\"Validation Batch {batch_idx + 1}/{len(data_loader)}, IoU: {avg_batch_iou:.4f}\")\n",
        "\n",
        "    avg_iou = total_iou / num_batches if num_batches > 0 else None\n",
        "    print(f\"Validation completed. Avg IoU: {avg_iou:.4f}\")\n",
        "    return None, avg_iou                                                        # No validation loss\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {'epoch': [], 'train_loss': [], 'val_loss': [], 'val_iou': []}\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10                                                                 # Number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Starting Epoch {epoch + 1}/{num_epochs}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
        "    print(\"Evaluating on validation set...\")\n",
        "    _, val_iou = evaluate(model, val_loader, device)                            # No validation loss\n",
        "\n",
        "    results['epoch'].append(epoch + 1)\n",
        "    results['train_loss'].append(train_loss)\n",
        "    results['val_loss'].append(None)                                            # No validation loss\n",
        "    results['val_iou'].append(val_iou)\n",
        "\n",
        "    # Apply learning rate scheduler\n",
        "    lr_scheduler.step(val_iou)                                                  # Adjust learning rate based on validation IoU\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(os.path.join(save_dir, 'training_results.csv'), index=False)\n",
        "\n",
        "    checkpoint_path = os.path.join(save_dir, f'model_epoch_{epoch + 1}.pth')\n",
        "    torch.save(model.state_dict(), checkpoint_path)\n",
        "    print(f\"Saved model checkpoint to {checkpoint_path}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Epoch {epoch + 1} completed in {(end_time - start_time):.2f} seconds\")\n",
        "    print(f\"Epoch {epoch + 1} Summary: Train Loss: {train_loss:.4f}, Validation IoU: {val_iou:.4f}\\n\")\n",
        "\n",
        "# Plot results\n",
        "def plot_results(results_csv):\n",
        "    import matplotlib.pyplot as plt\n",
        "    results_df = pd.read_csv(results_csv)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.plot(results_df['epoch'], results_df['train_loss'], label='Train Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.plot(results_df['epoch'], results_df['val_iou'], label='Validation IoU', color='green')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('IoU')\n",
        "    plt.title('Validation IoU Over Epochs')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_results(os.path.join(save_dir, 'training_results.csv'))"
      ],
      "metadata": {
        "id": "1z3nnmyBPytB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "import time\n",
        "import os\n",
        "import torchvision.ops as ops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Define and load the model\n",
        "# Ensure compatibility for both Google Colab and Kaggle\n",
        "if \"google.colab\" in str(get_ipython()):\n",
        "    save_dir = \"/content/global-wheat-detection/SecondModel\"\n",
        "else:\n",
        "    save_dir = \"/kaggle/working/SecondModel\"\n",
        "\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "def get_model():\n",
        "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    num_classes = 2                                                             # 1 class (wheat) + background\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "\n",
        "# Move model to device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Load last trained model checkpoint\n",
        "training_results_path = os.path.join(save_dir, 'training_results.csv')\n",
        "if os.path.exists(training_results_path):\n",
        "    results_df = pd.read_csv(training_results_path)\n",
        "    last_completed_epoch = results_df['epoch'].max()\n",
        "    print(f\"Last completed epoch: {last_completed_epoch}\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"No training results found. Make sure training has been completed before visualization.\")\n",
        "\n",
        "model_path = os.path.join(save_dir, f'model_epoch_{last_completed_epoch}.pth')\n",
        "if os.path.exists(model_path):\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "    print(f\"Loaded model from epoch {last_completed_epoch}\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Model checkpoint for epoch {last_completed_epoch} not found.\")\n",
        "\n",
        " Function to visualize bounding boxes with labels and image name\n",
        "def visualize_predictions(image_path, model, device, confidence_threshold=0.5):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    transform = T.ToTensor()\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model(image_tensor)\n",
        "\n",
        "    pred_boxes = predictions[0][\"boxes\"].cpu().numpy()\n",
        "    scores = predictions[0][\"scores\"].cpu().numpy()\n",
        "\n",
        "    filtered_boxes = pred_boxes[scores > confidence_threshold]\n",
        "    filtered_scores = scores[scores > confidence_threshold]\n",
        "\n",
        "    fig, ax = plt.subplots(1, figsize=(8, 6))\n",
        "    ax.imshow(image)\n",
        "\n",
        "    for box, score in zip(filtered_boxes, filtered_scores):\n",
        "        x_min, y_min, x_max, y_max = box\n",
        "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=2, edgecolor=\"r\", facecolor=\"none\")\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(x_min, y_min - 5, f'{score:.2f}', color='red', fontsize=10, weight='bold', bbox=dict(facecolor='white', alpha=0.5))\n",
        "\n",
        "    image_name = os.path.basename(image_path)\n",
        "    plt.title(f\"Predicted Bounding Boxes - {image_name}\")\n",
        "    plt.show()\n",
        "\n",
        "# Load test images and visualize\n",
        "if \"google.colab\" in str(get_ipython()):\n",
        "    test_dir = \"/content/global-wheat-detection/data/test\"\n",
        "else:\n",
        "    test_dir = \"/kaggle/input/global-wheat-detection/test\"\n",
        "\n",
        "test_images = [os.path.join(test_dir, f) for f in os.listdir(test_dir) if f.endswith(\".jpg\")]\n",
        "\n",
        "# Visualize bounding boxes for up to 10 test images\n",
        "for img_path in test_images[:10]:\n",
        "    visualize_predictions(img_path, model, device)\n"
      ],
      "metadata": {
        "id": "ZFTSSMCQdvez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Third Dry Run - K-Fold Cross-Validation (New Data Preparation applied)"
      ],
      "metadata": {
        "id": "AMw2iyqWfLya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import os\n",
        "import time\n",
        "import torchvision.ops as ops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Load Dataset with K-Fold Cross-Validation\n",
        "# Ensure compatibility for both Google Colab and Kaggle\n",
        "if \"google.colab\" in str(get_ipython()):\n",
        "    save_dir = \"/content/global-wheat-detection/ThirdModel\"\n",
        "    csv_file = \"/content/global-wheat-detection/data/train.csv\"\n",
        "    data_dir = \"/content/global-wheat-detection/data/train\"\n",
        "else:\n",
        "    save_dir = \"/kaggle/working/ThirdModel\"\n",
        "    csv_file = \"/kaggle/input/global-wheat-detection/train.csv\"\n",
        "    data_dir = \"/kaggle/input/global-wheat-detection/train\"\n",
        "\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "data = pd.read_csv(csv_file)\n",
        "\n",
        "def coco_to_frcnn(bbox):\n",
        "    x_min, y_min, width, height = bbox\n",
        "    x_max = x_min + width\n",
        "    y_max = y_min + height\n",
        "    return [x_min, y_min, x_max, y_max]\n",
        "\n",
        "data['bbox'] = data['bbox'].apply(eval)\n",
        "data['bbox_frcnn'] = data['bbox'].apply(coco_to_frcnn)\n",
        "annotations = {}\n",
        "for image_id, group in data.groupby('image_id'):\n",
        "    boxes = group['bbox_frcnn'].tolist()\n",
        "    annotations[image_id] = {\n",
        "        \"boxes\": torch.tensor(boxes, dtype=torch.float32),\n",
        "        \"labels\": torch.tensor([1] * len(boxes), dtype=torch.int64)\n",
        "    }\n",
        "\n",
        "image_ids = list(annotations.keys())\n",
        "\n",
        "class WheatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, image_ids, annotations, image_dir, transforms=None):\n",
        "        self.image_ids = image_ids\n",
        "        self.annotations = annotations\n",
        "        self.image_dir = image_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_id = self.image_ids[idx]\n",
        "        image_path = f\"{self.image_dir}/{image_id}.jpg\"\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        target = self.annotations[image_id]\n",
        "\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "dataset = WheatDataset(image_ids, annotations, data_dir, transforms=F.to_tensor)\n",
        "print(\"Dataset loaded successfully! Total images:\", len(dataset))"
      ],
      "metadata": {
        "id": "0ZsxZiczfPRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and load the model\n",
        "def get_model():\n",
        "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    num_classes = 2                                                             # 1 class (wheat) + background\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# Move model to device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {'fold': [], 'epoch': [], 'train_loss': [], 'val_iou': []}\n",
        "\n",
        "# Function to print current learning rate\n",
        "def print_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        print(f\"Current Learning Rate: {param_group['lr']:.6f}\")\n",
        "\n",
        "# IoU computation\n",
        "def compute_iou(pred_boxes, gt_boxes):\n",
        "    if len(pred_boxes) == 0 or len(gt_boxes) == 0:\n",
        "        return 0.0  # No detections or ground truth\n",
        "    iou = ops.box_iou(pred_boxes, gt_boxes)\n",
        "    return iou.mean().item()\n",
        "\n",
        "# Training loop\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch, total_epochs, fold):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    start_epoch_time = time.time()\n",
        "    for batch_idx, (images, targets) in enumerate(data_loader):\n",
        "        start_time = time.time()\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += losses.item()\n",
        "        end_time = time.time()\n",
        "        print(f\"Fold {fold + 1}/{k_folds}, Epoch {epoch + 1}/{total_epochs}, Batch {batch_idx + 1}/{len(data_loader)}, \"\n",
        "              f\"Loss: {losses.item():.4f}, Time: {end_time - start_time:.2f}s, \")\n",
        "    end_epoch_time = time.time()\n",
        "    print(f\"Epoch {epoch + 1} completed in {(end_epoch_time - start_epoch_time)/60:.2f} min\")\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "# Validation loop\n",
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    total_iou = 0.0\n",
        "    num_batches = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, targets) in enumerate(data_loader):\n",
        "            images = [img.to(device) for img in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            predictions = model(images)\n",
        "            batch_iou = 0.0\n",
        "            for pred, target in zip(predictions, targets):\n",
        "                pred_boxes = pred[\"boxes\"].detach().cpu()\n",
        "                gt_boxes = target[\"boxes\"].detach().cpu()\n",
        "                batch_iou += compute_iou(pred_boxes, gt_boxes)\n",
        "\n",
        "            total_iou += batch_iou / len(images) if len(images) > 0 else 0\n",
        "            num_batches += 1\n",
        "            print(f\"Validation Batch {batch_idx + 1}/{len(data_loader)}, IoU: {batch_iou:.4f}\")\n",
        "\n",
        "    return total_iou / num_batches if num_batches > 0 else 0\n",
        "\n",
        "# K-Fold Cross Validation\n",
        "k_folds = 3\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "indices = list(range(len(dataset)))\n",
        "batch_size = 4\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(indices)):\n",
        "    print(f\"Starting Fold {fold + 1}/{k_folds}\")\n",
        "\n",
        "    train_subset = Subset(dataset, train_idx)\n",
        "    val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "    model = get_model().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.0001)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
        "\n",
        "    for epoch in range(3):\n",
        "        print(f\"Fold {fold + 1}, Epoch {epoch + 1}\")\n",
        "        train_loss = train_one_epoch(model, optimizer, train_loader, device, epoch, 3, fold)\n",
        "        val_iou = evaluate(model, val_loader, device)\n",
        "\n",
        "        results['fold'].append(fold + 1)\n",
        "        results['epoch'].append(epoch + 1)\n",
        "        results['train_loss'].append(train_loss)\n",
        "        results['val_iou'].append(val_iou)\n",
        "\n",
        "        lr_scheduler.step(val_iou)\n",
        "        print_lr(optimizer)\n",
        "\n",
        "        # Save model checkpoint\n",
        "        checkpoint_path = os.path.join(save_dir, f'model_fold_{fold + 1}_epoch_{epoch + 1}.pth')\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "        print(f\"Model checkpoint saved at {checkpoint_path}\")\n",
        "\n",
        "        print(f\"Fold {fold + 1}, Epoch {epoch + 1} Summary: Train Loss: {train_loss:.4f}, Validation IoU: {val_iou:.4f}\")"
      ],
      "metadata": {
        "id": "ty1ch1Siitow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import os\n",
        "import time\n",
        "import torchvision.ops as ops\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure compatibility for both Google Colab and Kaggle\n",
        "if \"google.colab\" in str(get_ipython()):\n",
        "    save_dir = \"/content/global-wheat-detection/ThirdModel\"\n",
        "    test_dir = \"/content/global-wheat-detection/data/test\"\n",
        "else:\n",
        "    save_dir = \"/kaggle/working/ThirdModel\"\n",
        "    test_dir = \"/kaggle/input/global-wheat-detection/test\"\n",
        "\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Define and load the model\n",
        "def get_model():\n",
        "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    num_classes = 2  # 1 class (wheat) + background\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# Move model to device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Function to load trained model\n",
        "def load_model(fold_num, epoch_num):\n",
        "    model_path = os.path.join(save_dir, f\"model_fold_{fold_num}_epoch_{epoch_num}.pth\")\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Model checkpoint not found: {model_path}\")\n",
        "\n",
        "    model = get_model()\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"Loaded model from {model_path}\")\n",
        "    return model\n",
        "\n",
        "# Function to visualize predictions\n",
        "def visualize_predictions(image_path, model, device, confidence_threshold=0.5):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    transform = T.ToTensor()\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model(image_tensor)\n",
        "\n",
        "    pred_boxes = predictions[0][\"boxes\"].cpu().numpy()\n",
        "    scores = predictions[0][\"scores\"].cpu().numpy()\n",
        "\n",
        "    # Filter predictions by confidence threshold\n",
        "    filtered_boxes = pred_boxes[scores > confidence_threshold]\n",
        "    filtered_scores = scores[scores > confidence_threshold]\n",
        "\n",
        "    # Plot image with bounding boxes\n",
        "    fig, ax = plt.subplots(1, figsize=(8, 6))\n",
        "    ax.imshow(image)\n",
        "\n",
        "    for box, score in zip(filtered_boxes, filtered_scores):\n",
        "        x_min, y_min, x_max, y_max = box\n",
        "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=2, edgecolor=\"r\", facecolor=\"none\")\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(x_min, y_min - 5, f\"{score:.2f}\", color=\"red\", fontsize=10, weight=\"bold\")\n",
        "\n",
        "    plt.title(f\"{os.path.basename(image_path)}\")\n",
        "    plt.show()\n",
        "\n",
        "# Directory containing test images\n",
        "test_images = [os.path.join(test_dir, f) for f in os.listdir(test_dir) if f.endswith(\".jpg\")]\n",
        "\n",
        "# Load the best model based on the best-performing epoch\n",
        "csv_path = os.path.join(save_dir, 'training_results.csv')\n",
        "df = pd.read_csv(csv_path)\n",
        "best_epoch = df[\"epoch\"].max()  # Get the best epoch\n",
        "best_fold = df[\"fold\"].max()  # Get the best fold\n",
        "\n",
        "model = load_model(best_fold, best_epoch)\n",
        "\n",
        "# Visualize predictions for 10 test images\n",
        "for img_path in test_images[:10]:\n",
        "    visualize_predictions(img_path, model, device)"
      ],
      "metadata": {
        "id": "Phq7U0-TqUMi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}